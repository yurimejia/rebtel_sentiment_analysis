{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_rebtel = 'https://www.trustpilot.com/review/www.rebtel.com'\n",
    "url_rebtel_page = url_rebtel + '?page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(url_rebtel) as url:\n",
    "    homepage = url.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(homepage, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Rebtel Reviews | Customer Service Reviews of Rebtel | www.rebtel.com\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <script type=\"text/javascript\">\n",
      "   win\n"
     ]
    }
   ],
   "source": [
    "# Explore content of home page\n",
    "# list(soup.children)\n",
    "# soup.head\n",
    "print (soup.prettify()[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse content/reviews of home page\n",
    "reviews = soup.find_all('div', class_='review-stack')\n",
    "container = soup.find_all('div', class_='reviews-container')\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse total number of review pages\n",
    "pagination = soup.find_all('a', class_='pagination-page')\n",
    "page_num = [page['data-page-number'] for page in pagination]\n",
    "page_num = [int(page) for page in page_num if page != 'next-page']\n",
    "page_max = max(page_num)\n",
    "page_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Scrape all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []  # reviews is a list of dictionaries\n",
    "\n",
    "# Iterate over webpages\n",
    "for page in range(1, page_max + 1):\n",
    "    \n",
    "    # If first page, take url of homepage; otherwise, url + page\n",
    "    if (page == 1):\n",
    "        url_complete = url_rebtel\n",
    "    else:\n",
    "        url_complete = url_rebtel_page + str(page)\n",
    "    \n",
    "    # Get content of webpage\n",
    "    with urllib.request.urlopen(url_complete) as url:\n",
    "            page_content = url.read()        \n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    reviews = soup.find_all('div', class_='review-stack')\n",
    "    \n",
    "    # Iterate over reviews in page\n",
    "    for i in range(0, len(reviews)):  \n",
    "        # Parse user id\n",
    "        user_id = reviews[i].find('a', class_='user-review-name-link')['href'].strip()\n",
    "        user_id = user_id.replace('/users/', '')\n",
    "        \n",
    "        # Parse user name\n",
    "        user_name = reviews[i].find('a', class_='user-review-name-link').get_text().strip()\n",
    "        \n",
    "        # Parse review title\n",
    "        review_title = reviews[i].find('a', class_='review-title-link')\n",
    "        review_title = review_title.get_text().strip()\n",
    "        \n",
    "        # Parse review content\n",
    "        review_text = reviews[i].find('div', class_='review-body').get_text().strip()\n",
    "        \n",
    "        # Parse review answer\n",
    "        review_answer = reviews[i].find('div', class_='comment')\n",
    "        if (review_answer is not None):\n",
    "            review_answer = review_answer.get_text().strip()\n",
    "        else:\n",
    "            review_answer = None\n",
    "        \n",
    "        # Parse review stars\n",
    "        review_stars = int(reviews[i].find('div', class_='social-share-network social-share-network--twitter')['data-status'].split()[-5])\n",
    "        \n",
    "        # Parse review date\n",
    "        review_date = reviews[i].find('time', class_='ndate')['datetime'].strip()\n",
    "        review_date = review_date.replace('.000+00:00', '')\n",
    "        review_date = review_date.replace('T', ' ')\n",
    "        \n",
    "        # Parse whether review was verified by Rebtel\n",
    "        review_verify_text = reviews[i].find('div', class_='review-verified')\n",
    "        if (review_verify_text is not None):\n",
    "            review_verify = 'Verified order' in review_verify_text.get_text()\n",
    "        else:\n",
    "            review_verify = False        \n",
    "        \n",
    "        # Store data\n",
    "        data.append({  \n",
    "            'user_id': user_id,\n",
    "            'user': user_name,\n",
    "            'title': review_title,\n",
    "            'text': review_text,\n",
    "            'answer': review_answer,\n",
    "            'stars': review_stars,\n",
    "            'date': review_date,\n",
    "            'verify': review_verify\n",
    "        })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = time.strftime('%Y%m%d')\n",
    "file_name = '../data/rawdata_' + today + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(file_name, 'w') as outfile:  \n",
    "    json.dump(data, outfile, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [kpn]",
   "language": "python",
   "name": "Python [kpn]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
