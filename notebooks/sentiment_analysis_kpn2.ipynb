{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code from http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk import MaxentClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import collections, itertools\n",
    "from nltk import scores, sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to evaluate features\n",
    "def evaluate_classifier_original(featx,                         \n",
    "                        negtrain,\n",
    "                        negtest,\n",
    "                        postrain, \n",
    "                        postest,\n",
    "                        bestwords):    \n",
    "    \n",
    "    negtrain_feats = [(featx(w, bestwords), 'neg') for w in negtrain]\n",
    "    negtest_feats  = [(featx(w, bestwords), 'neg') for w in negtest]\n",
    "    postrain_feats = [(featx(w, bestwords), 'pos') for w in postrain]\n",
    "    postest_feats  = [(featx(w, bestwords), 'pos') for w in postest]\n",
    "    \n",
    "    trainfeats = negtrain_feats + postrain_feats\n",
    "    testfeats = negtest_feats + postest_feats     \n",
    "        \n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "    # classifier = MaxentClassifier.train(trainfeats)\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "            \n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "            refsets[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            testsets[observed].add(i)            \n",
    " \n",
    "    print('accuracy:' + str(nltk.classify.util.accuracy(classifier, testfeats)))\n",
    "    print('pos precision:'+ str(scores.precision(refsets['pos'], testsets['pos'])))\n",
    "    print('pos recall:' + str(scores.recall(refsets['pos'], testsets['pos'])))\n",
    "    print('neg precision:' + str(scores.precision(refsets['neg'], testsets['neg'])))\n",
    "    print('neg recall:' + str(scores.recall(refsets['neg'], testsets['neg'])))\n",
    "    classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate features\n",
    "def evaluate_classifier(featx,                         \n",
    "                        negtrain,\n",
    "                        negtest,\n",
    "                        postrain, \n",
    "                        postest):    \n",
    "    \n",
    "    negtrain_feats = [(featx(w), 'neg') for w in negtrain]\n",
    "    negtest_feats  = [(featx(w), 'neg') for w in negtest]\n",
    "    postrain_feats = [(featx(w), 'pos') for w in postrain]\n",
    "    postest_feats  = [(featx(w), 'pos') for w in postest]\n",
    "    \n",
    "    trainfeats = negtrain_feats + postrain_feats\n",
    "    testfeats = negtest_feats + postest_feats     \n",
    "        \n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "    # classifier = MaxentClassifier.train(trainfeats)\n",
    "    \n",
    "    actual = collections.defaultdict(set)\n",
    "    predict = collections.defaultdict(set)\n",
    " \n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "            actual[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            predict[observed].add(i)    \n",
    "            \n",
    "    \n",
    "    tp = len(set.intersection(actual['pos'], predict['pos']))\n",
    "    tn = len(set.intersection(actual['neg'], predict['neg']))\n",
    "    fn = len(set.intersection(actual['pos'], predict['neg']))\n",
    "    fp = len(set.intersection(actual['neg'], predict['pos']))\n",
    "    \n",
    "    return tp,tn,fn,fp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate features\n",
    "def evaluate_classifier2(featx,                         \n",
    "                        negtrain,\n",
    "                        negtest,\n",
    "                        postrain, \n",
    "                        postest,\n",
    "                        bestwords):    \n",
    "    \n",
    "    negtrain_feats = [(featx(w, bestwords), 'neg') for w in negtrain]\n",
    "    negtest_feats  = [(featx(w, bestwords), 'neg') for w in negtest]\n",
    "    postrain_feats = [(featx(w, bestwords), 'pos') for w in postrain]\n",
    "    postest_feats  = [(featx(w, bestwords), 'pos') for w in postest]\n",
    "    \n",
    "    trainfeats = negtrain_feats + postrain_feats\n",
    "    testfeats = negtest_feats + postest_feats     \n",
    "        \n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "    # classifier = MaxentClassifier.train(trainfeats)\n",
    "    \n",
    "    actual = collections.defaultdict(set)\n",
    "    predict = collections.defaultdict(set)\n",
    " \n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "            actual[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            predict[observed].add(i)    \n",
    "    \n",
    "    tp = len(set.intersection(actual['pos'], predict['pos']))\n",
    "    tn = len(set.intersection(actual['neg'], predict['neg']))\n",
    "    fn = len(set.intersection(actual['pos'], predict['neg']))\n",
    "    fp = len(set.intersection(actual['neg'], predict['pos']))\n",
    "    \n",
    "    return tp,tn,fn,fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words: All words\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stopword filtering\n",
    "stop_set = set(stopwords.words('english')) \n",
    "\n",
    "def stopword_filtered_word_feats(words, stopset = stop_set):\n",
    "    return dict([(word, True) for word in words if word not in stopset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bigram Collocations\n",
    "def bigram_word_feats(words, score_fn = BigramAssocMeasures.chi_sq, n = 200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminate Low Information Features\n",
    "# http://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/\n",
    "def get_best_words(neg_train, pos_train, best_n):\n",
    "    word_fd = FreqDist()\n",
    "    label_word_fd = ConditionalFreqDist()\n",
    "\n",
    "    for w in [word for review in neg_train for word in review]:\n",
    "        word_fd[w.lower()] += 1\n",
    "        label_word_fd['neg'][w.lower()] += 1\n",
    "\n",
    "    for w in [word for review in pos_train for word in review]:\n",
    "        word_fd[w.lower()] += 1\n",
    "        label_word_fd['pos'][w.lower()] += 1\n",
    "\n",
    "    neg_word_count = label_word_fd['neg'].N()\n",
    "    pos_word_count = label_word_fd['pos'].N()    \n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "\n",
    "    word_scores = {}\n",
    "    for word, freq in word_fd.items():\n",
    "        pos_score = BigramAssocMeasures.chi_sq( \\\n",
    "            label_word_fd['pos'][word], \\\n",
    "            (freq, pos_word_count), \\\n",
    "            total_word_count)\n",
    "        neg_score = BigramAssocMeasures.chi_sq( \\\n",
    "            label_word_fd['neg'][word], \\\n",
    "            (freq, neg_word_count), \\\n",
    "            total_word_count)\n",
    "        word_scores[word] = pos_score + neg_score\n",
    "\n",
    "    best = sorted(word_scores.items(), \\\n",
    "                  key = lambda s: s[1], \\\n",
    "                  reverse = True)[:best_n]    \n",
    "    return set([w for w, s in best])\n",
    "    \n",
    "def best_word_feats(words, bestwords):\n",
    "    return dict([(word, True) for word in words if word in bestwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best words + bigram\n",
    "def best_bigram_word_feats(words, \n",
    "                           bestwords,\n",
    "                           score_fn = BigramAssocMeasures.chi_sq, \n",
    "                           n = 200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    d = dict([(bigram, True) for bigram in bigrams])\n",
    "    d.update(best_word_feats(words, bestwords))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_name = '/home/yuri/Dropbox/Compartido/Projects_professional/kpn/data/rawdata_20170620.json'\n",
    "with open(file_name) as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2239, 8),)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(punctuation)])\n",
    "    return s\n",
    "\n",
    "rem = string.punctuation\n",
    "pattern = r\"[{}]\".format(rem)\n",
    "\n",
    "df['text_nopunct'] = df['text'].str.replace(pattern, ' ')\n",
    "\n",
    "#df['text_nopunct'] = df['text'].apply(remove_punctuation)\n",
    "#df['text_nopunct'] = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((487, 9), (1525, 9), (227, 9))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split reviews: negative vs positive vs neutral\n",
    "# df_neg = df[df.stars == 1]\n",
    "# df_pos = df[df.stars == 5]\n",
    "\n",
    "df_neg = df[(df.stars == 1) | (df.stars == 2)]\n",
    "df_pos = df[(df.stars == 4) | (df.stars == 5)]\n",
    "df_neu = df[(df.stars == 3)]\n",
    "df_neg.shape, df_pos.shape, df_neu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_neg.text_nopunct[5];\n",
    "df_neu.text_nopunct[:20];\n",
    "df_pos.text_nopunct[:6];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split review: positive vs negative\n",
    "neg_words = [word_tokenize(f) for f in df_neg.text_nopunct]\n",
    "pos_words = [word_tokenize(f) for f in df_pos.text_nopunct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(neg_words[6]), neg_words[10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data set: developing vs validation\n",
    "neg_develop, neg_val = train_test_split(neg_words, test_size=0.25)\n",
    "pos_develop, pos_val = train_test_split(pos_words, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 122, 1143, 382)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_develop),len(neg_val), len(pos_develop),len(pos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "k = 5\n",
    "results = collections.defaultdict(dict)\n",
    "models = ['bag_of_words', 'stop_words', 'bigram', \\\n",
    "          'best_words', 'bigram_best_words']\n",
    "\n",
    "for model_name in models:\n",
    "    results[model_name]['accuracy'] = []\n",
    "    results[model_name]['pos_precision'] = []\n",
    "    results[model_name]['pos_recall'] = []\n",
    "    results[model_name]['neg_precision'] = []\n",
    "    results[model_name]['neg_recall'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "54 73 175 0\n",
      "1. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "45 73 184 0\n",
      "2. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "47 72 182 1\n",
      "3. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "38 72 191 1\n",
      "4. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "47 72 182 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, k):\n",
    "    # Split developing data set: training vs testing\n",
    "    neg_train, neg_test = train_test_split(neg_develop, test_size=1/k)\n",
    "    pos_train, pos_test = train_test_split(pos_develop, test_size=1/k)    \n",
    "        \n",
    "    num_train = len(neg_train) + len(pos_train)\n",
    "    num_test = len(neg_test) + len(pos_test)    \n",
    "    print(str(i) + '. Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "    \n",
    "    model_name = 'bag_of_words'\n",
    "    print(model_name.upper())        \n",
    "    tp,tn,fn,fp = evaluate_classifier(word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test)\n",
    "    print(str(tp) + ' ' + str(tn) + ' ' + str(fn) + ' ' + str(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206,\n",
       " 292,\n",
       " 914,\n",
       " 302,\n",
       " 73,\n",
       " 229,\n",
       " ({'Rebtel': True,\n",
       "   'connection': True,\n",
       "   'drops': True,\n",
       "   'often': True,\n",
       "   'very': True},\n",
       "  'neg'),\n",
       " 'pos')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negtrain_feats = [(word_feats(w), 'neg') for w in neg_train]\n",
    "negtest_feats  = [(word_feats(w), 'neg') for w in neg_test]\n",
    "postrain_feats = [(word_feats(w), 'pos') for w in pos_train]\n",
    "postest_feats  = [(word_feats(w), 'pos') for w in pos_test]\n",
    "\n",
    "trainfeats = negtrain_feats + postrain_feats\n",
    "testfeats = negtest_feats + postest_feats     \n",
    "\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "#classifier = MaxentClassifier.train(trainfeats)\n",
    "\n",
    "actual = collections.defaultdict(set)\n",
    "predict = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(testfeats):\n",
    "        actual[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        predict[observed].add(i)    \n",
    "\n",
    "\n",
    "tp = set.intersection(actual['pos'], predict['pos'])\n",
    "tn = set.intersection(actual['neg'], predict['neg'])\n",
    "fn = set.intersection(actual['pos'], predict['neg'])\n",
    "fp = set.intersection(actual['neg'], predict['pos'])\n",
    "\n",
    "\n",
    "#tp,tn,fn,fp,\\\n",
    "len(trainfeats), len(negtrain_feats), len(postrain_feats), \\\n",
    "len(testfeats), len(negtest_feats), len(postest_feats), \\\n",
    "testfeats[33] , classifier.classify(testfeats[33][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text1 = word_tokenize('I think rebtel is awesome')\n",
    "my_text2 = word_tokenize('Rebtel is terrible')\n",
    "my_text3 = word_tokenize('the service sucks')\n",
    "my_text4 = word_tokenize('the service is good')\n",
    "my_text5 = word_tokenize('I want my mone back')\n",
    "my_text6 = word_tokenize('the service is very expensive')\n",
    "my_text7 = word_tokenize('good deal for online service telephone')\n",
    "\n",
    "classifier.classify(word_feats(my_text1)),\\\n",
    "classifier.classify(word_feats(my_text2)),\\\n",
    "classifier.classify(word_feats(my_text3)),\\\n",
    "classifier.classify(word_feats(my_text4)),\\\n",
    "classifier.classify(word_feats(my_text5)),\\\n",
    "classifier.classify(word_feats(my_text6)),\\\n",
    "classifier.classify(word_feats(my_text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_words = get_best_words(neg_train, pos_train, 2000)\n",
    "len(best_words), best_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Train on 1194 instances, test on 300 instances\n",
      "BAG_OF_WORDS\n",
      "STOP_WORDS\n",
      "BIGRAM\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-2c57f302d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mpostrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mpostest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         bestwords = best_words)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_precision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-f39a4c64e6f7>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[0;34m(featx, negtrain, negtest, postrain, postest, bestwords)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-f39a4c64e6f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2e8fc1cf17d8>\u001b[0m in \u001b[0;36mbigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(0, k):\n",
    "    # Split developing data set: training vs testing\n",
    "    neg_train, neg_test = train_test_split(neg_develop, test_size=1/k)\n",
    "    pos_train, pos_test = train_test_split(pos_develop, test_size=1/k)    \n",
    "    best_words = get_best_words(neg_train, pos_train, 10000)\n",
    "    \n",
    "    num_train = len(neg_train) + len(pos_train)\n",
    "    num_test = len(neg_test) + len(pos_test)    \n",
    "    print(str(i) + '. Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "    \n",
    "    model_name = 'bag_of_words'\n",
    "    print(model_name.upper())        \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall)\n",
    "    \n",
    "    \n",
    "    model_name = 'stop_words'\n",
    "    print(model_name.upper())     \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(stopword_filtered_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "            \n",
    "    \n",
    "    model_name = 'bigram'\n",
    "    print(model_name.upper())     \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(bigram_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall)\n",
    "    \n",
    "                     \n",
    "    model_name = 'best_words'    \n",
    "    print(model_name.upper())            \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(best_word_feats,                        \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)    \n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "    \n",
    "                    \n",
    "    model_name = 'bigram_best_words'\n",
    "    print(model_name.upper())         \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(best_bigram_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>neg_recall</th>\n",
       "      <th>pos_precision</th>\n",
       "      <th>pos_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bag_of_words</th>\n",
       "      <td>0.280945</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.994366</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>0.210480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram_best_words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_words</th>\n",
       "      <td>0.329592</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.985012</td>\n",
       "      <td>0.381659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neg_precision  accuracy  neg_recall  pos_precision  \\\n",
       "bag_of_words            0.280945  0.396000    0.994366       0.992450   \n",
       "best_words                   NaN       NaN         NaN            NaN   \n",
       "bigram                       NaN       NaN         NaN            NaN   \n",
       "bigram_best_words            NaN       NaN         NaN            NaN   \n",
       "stop_words              0.329592  0.523333    0.980282       0.985012   \n",
       "\n",
       "                   pos_recall  \n",
       "bag_of_words         0.210480  \n",
       "best_words                NaN  \n",
       "bigram                    NaN  \n",
       "bigram_best_words         NaN  \n",
       "stop_words           0.381659  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose Best Model (Features)\n",
    "best_features = collections.defaultdict(dict)\n",
    "for model_name in models:\n",
    "    best_features[model_name]['accuracy'] = mean(results[model_name]['accuracy'])\n",
    "    best_features[model_name]['pos_precision'] = mean(results[model_name]['pos_precision'])\n",
    "    best_features[model_name]['pos_recall'] = mean(results[model_name]['pos_recall'])\n",
    "    best_features[model_name]['neg_precision'] = mean(results[model_name]['neg_precision'])\n",
    "    best_features[model_name]['neg_recall'] = mean(results[model_name]['neg_recall'])\n",
    "\n",
    "pd.DataFrame.from_dict({(i): best_features[i]  \n",
    "                        for i in best_features.keys()}, \n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. STOP_WORDS\n"
     ]
    }
   ],
   "source": [
    "model_name = 'stop_words'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "ref, pred = evaluate_classifier(stopword_filtered_word_feats,                         \n",
    "                    negtrain = neg_train,\n",
    "                    negtest = neg_test,\n",
    "                    postrain = pos_train, \n",
    "                    postest = pos_test,\n",
    "                    bestwords = best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 67, 144, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set.intersection(ref['pos'], pred['pos'])),\\\n",
    "len(set.intersection(ref['neg'], pred['neg'])),\\\n",
    "len(set.intersection(ref['pos'], pred['neg'])),\\\n",
    "len(set.intersection(ref['neg'], pred['pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WORDS\n"
     ]
    }
   ],
   "source": [
    "model_name = 'best_words'    \n",
    "print(model_name.upper())            \n",
    "ref, pred = evaluate_classifier(\n",
    "    best_word_feats,                        \n",
    "    negtrain = neg_train,\n",
    "    negtest = neg_test,\n",
    "    postrain = pos_train, \n",
    "    postest = pos_test,\n",
    "    bestwords = best_words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 71, 912, 229)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train), len(neg_test), len(pos_train), len(pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. BEST_BIGRAMS\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-25aa22f24e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_bigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-25aa22f24e2b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_bigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-44dc700284e9>\u001b[0m in \u001b[0;36mbest_bigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m                            n = 200):\n\u001b[1;32m      6\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "model_name = 'best_bigrams'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "\n",
    "#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\n",
    "#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\n",
    "postrain_feats = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_train]\n",
    "#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2458f428a635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpostrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpostest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     bestwords = best_words)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f39a4c64e6f7>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[0;34m(featx, negtrain, negtest, postrain, postest, bestwords)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f39a4c64e6f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2e8fc1cf17d8>\u001b[0m in \u001b[0;36mbigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "model_name = 'bigram'\n",
    "print(model_name.upper())     \n",
    "evaluate_classifier(\n",
    "    bigram_word_feats,                         \n",
    "    negtrain = neg_train,\n",
    "    negtest = neg_test,\n",
    "    postrain = pos_train, \n",
    "    postest = pos_test,\n",
    "    bestwords = best_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST MODEL: TRAIN ON FULL DEVELOPING DATA SET, TEST ON VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1494 instances, test on 499 instances\n",
      "4. BIGRAM_BEST_WORDS\n",
      "accuracy:0.43286573146292584\n",
      "pos precision:0.9803921568627451\n",
      "pos recall:0.26246719160104987\n",
      "neg precision:0.29219143576826195\n",
      "neg recall:0.9830508474576272\n",
      "Most Informative Features\n",
      "                       # = True              neg : pos    =     50.5 : 1.0\n",
      "               contacted = True              neg : pos    =     48.4 : 1.0\n",
      "                  refund = True              neg : pos    =     38.1 : 1.0\n",
      "                  saying = True              neg : pos    =     36.8 : 1.0\n",
      "                response = True              neg : pos    =     36.4 : 1.0\n",
      "         ('my', 'money') = True              neg : pos    =     34.2 : 1.0\n",
      "                      20 = True              neg : pos    =     31.2 : 1.0\n",
      "                  cancel = True              neg : pos    =     31.2 : 1.0\n",
      "         ('and', 'when') = True              neg : pos    =     29.0 : 1.0\n",
      "                  unable = True              neg : pos    =     29.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "best_words = get_best_words(neg_develop, pos_develop, 10000)\n",
    "num_train = len(neg_develop) + len(pos_develop)\n",
    "num_test = len(neg_val) + len(pos_val)    \n",
    "\n",
    "print('Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "\n",
    "model_name = 'bigram_best_words'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "evaluate_classifier_original(best_bigram_word_feats,\n",
    "                             negtrain = neg_develop,\n",
    "                             negtest = neg_val,\n",
    "                             postrain = pos_develop, \n",
    "                             postest = pos_val,\n",
    "                             bestwords = best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3, 8, 8]\n",
    "y_true = [0, 1, 2, 3, 7, 5]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function recall in module nltk.metrics.scores:\n",
      "\n",
      "recall(reference, test)\n",
      "    Given a set of reference values and a set of test values, return\n",
      "    the fraction of reference values that appear in the test set.\n",
      "    In particular, return card(``reference`` intersection ``test``)/card(``reference``).\n",
      "    If ``reference`` is empty, then return None.\n",
      "    \n",
      "    :type reference: set\n",
      "    :param reference: A set of reference values.\n",
      "    :type test: set\n",
      "    :param test: A set of values to compare against the reference set.\n",
      "    :rtype: float or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scores.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function precision in module nltk.metrics.scores:\n",
      "\n",
      "precision(reference, test)\n",
      "    Given a set of reference values and a set of test values, return\n",
      "    the fraction of test values that appear in the reference set.\n",
      "    In particular, return card(``reference`` intersection ``test``)/card(``test``).\n",
      "    If ``test`` is empty, then return None.\n",
      "    \n",
      "    :type reference: set\n",
      "    :param reference: A set of reference values.\n",
      "    :type test: set\n",
      "    :param test: A set of values to compare against the reference set.\n",
      "    :rtype: float or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scores.precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "TextBlob('yuri is super awesome and positive').sentiment\n",
    "zen = TextBlob(\"Beautiful is better than ugly.\"\n",
    "               \" Explicit is better than implicit.\"\n",
    "               \" Simple is better than complex.\")\n",
    "zen2 = TextBlob('This is my first sentence. This is a second one.')\n",
    "zen.words, zen.sentences, zen2.sentences\n",
    "for sentence in zen.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.sentiment)\n",
    "    from textblob import Word\n",
    "\n",
    "w1 = Word(\"octopi\")\n",
    "w2 = Word(\"went\")\n",
    "w1.lemmatize(), w2.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"results\")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('reslults').correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [kpn]",
   "language": "python",
   "name": "Python [kpn]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
