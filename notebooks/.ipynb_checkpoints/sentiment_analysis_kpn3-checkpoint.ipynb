{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Code from http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk import MaxentClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import collections, itertools\n",
    "from nltk import scores, sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from textblob import Word\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_name = 'rawdata_20170620.json'\n",
    "with open(file_name) as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove punctuation and numerical characters\n",
    "rem = string.punctuation\n",
    "pattern = r\"[{}]\".format(rem)\n",
    "\n",
    "df['text_nopunct'] = df['text'].str.replace(pattern, ' ')\n",
    "df['text_nopunct'] = df['text_nopunct'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text_nopunct'][:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.51000662],\n",
       "       [ 0.51000662,  1.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity = [TextBlob(review).sentiment[0] for review in df.text_nopunct]\n",
    "subjectivity = [TextBlob(review).sentiment[1] for review in df.text_nopunct]\n",
    "stars = df.stars\n",
    "np.corrcoef(polarity, stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['polarity'] = polarity\n",
    "df['subjectivity'] = subjectivity\n",
    "df.head(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b7fbba278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df['polarity'].hist(by = df['stars']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngpmZVf4ba6qcqye/U2oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b7f783588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df['subjectivity'].hist(by = df['stars']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('stars').describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split reviews: negative vs positive vs neutral\n",
    "df_neg = df[(df.stars == 1) | (df.stars == 2)]\n",
    "df_pos = df[(df.stars == 4) | (df.stars == 5)]\n",
    "df_neu = df[(df.stars == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_neg.text_nopunct[:5], df_neg.stars[:5];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split review: positive vs negative\n",
    "neg_words = [word_tokenize(w) for w in df_neg.text_nopunct]\n",
    "pos_words = [word_tokenize(w) for w in df_pos.text_nopunct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(neg_words[6]), neg_words[10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data set: developing vs validation\n",
    "neg_develop, neg_val = train_test_split(neg_words, test_size=0.25)\n",
    "pos_develop, pos_val = train_test_split(pos_words, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 122, 1143, 382)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_develop),len(neg_val), len(pos_develop),len(pos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "k = 5\n",
    "results = collections.defaultdict(dict)\n",
    "models = ['bag_of_words', 'stop_words', 'bigram', \\\n",
    "          'best_words', 'bigram_best_words']\n",
    "\n",
    "for model_name in models:\n",
    "    results[model_name]['accuracy'] = []\n",
    "    results[model_name]['pos_precision'] = []\n",
    "    results[model_name]['pos_recall'] = []\n",
    "    results[model_name]['neg_precision'] = []\n",
    "    results[model_name]['neg_recall'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "54 73 175 0\n",
      "1. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "45 73 184 0\n",
      "2. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "47 72 182 1\n",
      "3. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "38 72 191 1\n",
      "4. Train on 1206 instances, test on 302 instances\n",
      "BAG_OF_WORDS\n",
      "47 72 182 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, k):\n",
    "    # Split developing data set: training vs testing\n",
    "    neg_train, neg_test = train_test_split(neg_develop, test_size=1/k)\n",
    "    pos_train, pos_test = train_test_split(pos_develop, test_size=1/k)    \n",
    "        \n",
    "    num_train = len(neg_train) + len(pos_train)\n",
    "    num_test = len(neg_test) + len(pos_test)    \n",
    "    print(str(i) + '. Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "    \n",
    "    model_name = 'bag_of_words'\n",
    "    print(model_name.upper())        \n",
    "    tp,tn,fn,fp = evaluate_classifier(word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test)\n",
    "    print(str(tp) + ' ' + str(tn) + ' ' + str(fn) + ' ' + str(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206,\n",
       " 292,\n",
       " 914,\n",
       " 302,\n",
       " 73,\n",
       " 229,\n",
       " ({'Rebtel': True,\n",
       "   'connection': True,\n",
       "   'drops': True,\n",
       "   'often': True,\n",
       "   'very': True},\n",
       "  'neg'),\n",
       " 'pos')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negtrain_feats = [(word_feats(w), 'neg') for w in neg_train]\n",
    "negtest_feats  = [(word_feats(w), 'neg') for w in neg_test]\n",
    "postrain_feats = [(word_feats(w), 'pos') for w in pos_train]\n",
    "postest_feats  = [(word_feats(w), 'pos') for w in pos_test]\n",
    "\n",
    "trainfeats = negtrain_feats + postrain_feats\n",
    "testfeats = negtest_feats + postest_feats     \n",
    "\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "#classifier = MaxentClassifier.train(trainfeats)\n",
    "\n",
    "actual = collections.defaultdict(set)\n",
    "predict = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(testfeats):\n",
    "        actual[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        predict[observed].add(i)    \n",
    "\n",
    "\n",
    "tp = set.intersection(actual['pos'], predict['pos'])\n",
    "tn = set.intersection(actual['neg'], predict['neg'])\n",
    "fn = set.intersection(actual['pos'], predict['neg'])\n",
    "fp = set.intersection(actual['neg'], predict['pos'])\n",
    "\n",
    "\n",
    "#tp,tn,fn,fp,\\\n",
    "len(trainfeats), len(negtrain_feats), len(postrain_feats), \\\n",
    "len(testfeats), len(negtest_feats), len(postest_feats), \\\n",
    "testfeats[33] , classifier.classify(testfeats[33][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text1 = word_tokenize('I think rebtel is awesome')\n",
    "my_text2 = word_tokenize('Rebtel is terrible')\n",
    "my_text3 = word_tokenize('the service sucks')\n",
    "my_text4 = word_tokenize('the service is good')\n",
    "my_text5 = word_tokenize('I want my mone back')\n",
    "my_text6 = word_tokenize('the service is very expensive')\n",
    "my_text7 = word_tokenize('good deal for online service telephone')\n",
    "\n",
    "classifier.classify(word_feats(my_text1)),\\\n",
    "classifier.classify(word_feats(my_text2)),\\\n",
    "classifier.classify(word_feats(my_text3)),\\\n",
    "classifier.classify(word_feats(my_text4)),\\\n",
    "classifier.classify(word_feats(my_text5)),\\\n",
    "classifier.classify(word_feats(my_text6)),\\\n",
    "classifier.classify(word_feats(my_text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_words = get_best_words(neg_train, pos_train, 2000)\n",
    "len(best_words), best_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Train on 1194 instances, test on 300 instances\n",
      "BAG_OF_WORDS\n",
      "STOP_WORDS\n",
      "BIGRAM\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-2c57f302d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mpostrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mpostest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         bestwords = best_words)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_precision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-f39a4c64e6f7>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[0;34m(featx, negtrain, negtest, postrain, postest, bestwords)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-f39a4c64e6f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-2e8fc1cf17d8>\u001b[0m in \u001b[0;36mbigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(0, k):\n",
    "    # Split developing data set: training vs testing\n",
    "    neg_train, neg_test = train_test_split(neg_develop, test_size=1/k)\n",
    "    pos_train, pos_test = train_test_split(pos_develop, test_size=1/k)    \n",
    "    best_words = get_best_words(neg_train, pos_train, 10000)\n",
    "    \n",
    "    num_train = len(neg_train) + len(pos_train)\n",
    "    num_test = len(neg_test) + len(pos_test)    \n",
    "    print(str(i) + '. Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "    \n",
    "    model_name = 'bag_of_words'\n",
    "    print(model_name.upper())        \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall)\n",
    "    \n",
    "    \n",
    "    model_name = 'stop_words'\n",
    "    print(model_name.upper())     \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(stopword_filtered_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "            \n",
    "    \n",
    "    model_name = 'bigram'\n",
    "    print(model_name.upper())     \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(bigram_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall)\n",
    "    \n",
    "                     \n",
    "    model_name = 'best_words'    \n",
    "    print(model_name.upper())            \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(best_word_feats,                        \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)    \n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "    \n",
    "                    \n",
    "    model_name = 'bigram_best_words'\n",
    "    print(model_name.upper())         \n",
    "    accuracy, pos_precision, pos_recall, neg_precision, neg_recall = \\\n",
    "    evaluate_classifier(best_bigram_word_feats,                         \n",
    "                        negtrain = neg_train,\n",
    "                        negtest = neg_test,\n",
    "                        postrain = pos_train, \n",
    "                        postest = pos_test,\n",
    "                        bestwords = best_words)\n",
    "    results[model_name]['accuracy'].append(accuracy)\n",
    "    results[model_name]['pos_precision'].append(pos_precision)\n",
    "    results[model_name]['pos_recall'].append(pos_recall)\n",
    "    results[model_name]['neg_precision'].append(neg_precision)\n",
    "    results[model_name]['neg_recall'].append(neg_recall) \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>neg_recall</th>\n",
       "      <th>pos_precision</th>\n",
       "      <th>pos_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bag_of_words</th>\n",
       "      <td>0.280945</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.994366</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>0.210480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram_best_words</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_words</th>\n",
       "      <td>0.329592</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.985012</td>\n",
       "      <td>0.381659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neg_precision  accuracy  neg_recall  pos_precision  \\\n",
       "bag_of_words            0.280945  0.396000    0.994366       0.992450   \n",
       "best_words                   NaN       NaN         NaN            NaN   \n",
       "bigram                       NaN       NaN         NaN            NaN   \n",
       "bigram_best_words            NaN       NaN         NaN            NaN   \n",
       "stop_words              0.329592  0.523333    0.980282       0.985012   \n",
       "\n",
       "                   pos_recall  \n",
       "bag_of_words         0.210480  \n",
       "best_words                NaN  \n",
       "bigram                    NaN  \n",
       "bigram_best_words         NaN  \n",
       "stop_words           0.381659  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose Best Model (Features)\n",
    "best_features = collections.defaultdict(dict)\n",
    "for model_name in models:\n",
    "    best_features[model_name]['accuracy'] = mean(results[model_name]['accuracy'])\n",
    "    best_features[model_name]['pos_precision'] = mean(results[model_name]['pos_precision'])\n",
    "    best_features[model_name]['pos_recall'] = mean(results[model_name]['pos_recall'])\n",
    "    best_features[model_name]['neg_precision'] = mean(results[model_name]['neg_precision'])\n",
    "    best_features[model_name]['neg_recall'] = mean(results[model_name]['neg_recall'])\n",
    "\n",
    "pd.DataFrame.from_dict({(i): best_features[i]  \n",
    "                        for i in best_features.keys()}, \n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. STOP_WORDS\n"
     ]
    }
   ],
   "source": [
    "model_name = 'stop_words'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "ref, pred = evaluate_classifier(stopword_filtered_word_feats,                         \n",
    "                    negtrain = neg_train,\n",
    "                    negtest = neg_test,\n",
    "                    postrain = pos_train, \n",
    "                    postest = pos_test,\n",
    "                    bestwords = best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 67, 144, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set.intersection(ref['pos'], pred['pos'])),\\\n",
    "len(set.intersection(ref['neg'], pred['neg'])),\\\n",
    "len(set.intersection(ref['pos'], pred['neg'])),\\\n",
    "len(set.intersection(ref['neg'], pred['pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WORDS\n"
     ]
    }
   ],
   "source": [
    "model_name = 'best_words'    \n",
    "print(model_name.upper())            \n",
    "ref, pred = evaluate_classifier(\n",
    "    best_word_feats,                        \n",
    "    negtrain = neg_train,\n",
    "    negtest = neg_test,\n",
    "    postrain = pos_train, \n",
    "    postest = pos_test,\n",
    "    bestwords = best_words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 71, 912, 229)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train), len(neg_test), len(pos_train), len(pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. BEST_BIGRAMS\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-25aa22f24e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_bigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-25aa22f24e2b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_bigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-44dc700284e9>\u001b[0m in \u001b[0;36mbest_bigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m                            n = 200):\n\u001b[1;32m      6\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "model_name = 'best_bigrams'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "\n",
    "#negtrain_feats = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_train]\n",
    "#negtest_feats  = [(best_bigram_word_feats(w, best_words), 'neg') for w in neg_test]\n",
    "postrain_feats = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_train]\n",
    "#postest_feats  = [(best_bigram_word_feats(w, best_words), 'pos') for w in pos_test]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2458f428a635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpostrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpostest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     bestwords = best_words)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f39a4c64e6f7>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[0;34m(featx, negtrain, negtest, postrain, postest, bestwords)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f39a4c64e6f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnegtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnegtest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpostrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpostest_feats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpostest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2e8fc1cf17d8>\u001b[0m in \u001b[0;36mbigram_word_feats\u001b[0;34m(words, bestwords, score_fn, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbigram_word_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramAssocMeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi_sq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbigram_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mnbest\u001b[0;34m(self, score_fn, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Returns the top n ngrams when scored by the given function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabove_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mlowest\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetermined\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36m_score_ngrams\u001b[0;34m(self, score_fn)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ngram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/collocations.py\u001b[0m in \u001b[0;36mscore_ngram\u001b[0;34m(self, score_fn, w1, w2)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mn_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mn_xi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_fd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mchi_sq\u001b[0;34m(cls, n_ii, n_ix_xi_tuple, n_xx)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ix_xi_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuri/anaconda2/envs/kpn/lib/python3.4/site-packages/nltk/metrics/association.py\u001b[0m in \u001b[0;36mphi_sq\u001b[0;34m(cls, *marginals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         return ((n_ii*n_oo - n_io*n_oi)**2 /\n\u001b[0;32m--> 213\u001b[0;31m                 ((n_ii + n_io) * (n_ii + n_oi) * (n_io + n_oo) * (n_oi + n_oo)))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "model_name = 'bigram'\n",
    "print(model_name.upper())     \n",
    "evaluate_classifier(\n",
    "    bigram_word_feats,                         \n",
    "    negtrain = neg_train,\n",
    "    negtest = neg_test,\n",
    "    postrain = pos_train, \n",
    "    postest = pos_test,\n",
    "    bestwords = best_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST MODEL: TRAIN ON FULL DEVELOPING DATA SET, TEST ON VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1494 instances, test on 499 instances\n",
      "4. BIGRAM_BEST_WORDS\n",
      "accuracy:0.43286573146292584\n",
      "pos precision:0.9803921568627451\n",
      "pos recall:0.26246719160104987\n",
      "neg precision:0.29219143576826195\n",
      "neg recall:0.9830508474576272\n",
      "Most Informative Features\n",
      "                       # = True              neg : pos    =     50.5 : 1.0\n",
      "               contacted = True              neg : pos    =     48.4 : 1.0\n",
      "                  refund = True              neg : pos    =     38.1 : 1.0\n",
      "                  saying = True              neg : pos    =     36.8 : 1.0\n",
      "                response = True              neg : pos    =     36.4 : 1.0\n",
      "         ('my', 'money') = True              neg : pos    =     34.2 : 1.0\n",
      "                      20 = True              neg : pos    =     31.2 : 1.0\n",
      "                  cancel = True              neg : pos    =     31.2 : 1.0\n",
      "         ('and', 'when') = True              neg : pos    =     29.0 : 1.0\n",
      "                  unable = True              neg : pos    =     29.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "best_words = get_best_words(neg_develop, pos_develop, 10000)\n",
    "num_train = len(neg_develop) + len(pos_develop)\n",
    "num_test = len(neg_val) + len(pos_val)    \n",
    "\n",
    "print('Train on %d instances, test on %d instances' % (num_train, num_test)) \n",
    "\n",
    "model_name = 'bigram_best_words'\n",
    "print(str(i) + '. ' + model_name.upper()) \n",
    "evaluate_classifier_original(best_bigram_word_feats,\n",
    "                             negtrain = neg_develop,\n",
    "                             negtest = neg_val,\n",
    "                             postrain = pos_develop, \n",
    "                             postest = pos_val,\n",
    "                             bestwords = best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3, 8, 8]\n",
    "y_true = [0, 1, 2, 3, 7, 5]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function recall in module nltk.metrics.scores:\n",
      "\n",
      "recall(reference, test)\n",
      "    Given a set of reference values and a set of test values, return\n",
      "    the fraction of reference values that appear in the test set.\n",
      "    In particular, return card(``reference`` intersection ``test``)/card(``reference``).\n",
      "    If ``reference`` is empty, then return None.\n",
      "    \n",
      "    :type reference: set\n",
      "    :param reference: A set of reference values.\n",
      "    :type test: set\n",
      "    :param test: A set of values to compare against the reference set.\n",
      "    :rtype: float or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scores.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function precision in module nltk.metrics.scores:\n",
      "\n",
      "precision(reference, test)\n",
      "    Given a set of reference values and a set of test values, return\n",
      "    the fraction of test values that appear in the reference set.\n",
      "    In particular, return card(``reference`` intersection ``test``)/card(``test``).\n",
      "    If ``test`` is empty, then return None.\n",
      "    \n",
      "    :type reference: set\n",
      "    :param reference: A set of reference values.\n",
      "    :type test: set\n",
      "    :param test: A set of values to compare against the reference set.\n",
      "    :rtype: float or None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scores.precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [kpn]",
   "language": "python",
   "name": "Python [kpn]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
